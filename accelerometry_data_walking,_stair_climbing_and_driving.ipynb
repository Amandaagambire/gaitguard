{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGMI0Gsy_Yng"
      },
      "source": [
        "# **SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Mv8mnMES_cQB"
      },
      "outputs": [],
      "source": [
        "# input | nothing\n",
        "import os # used for exploring file system\n",
        "from itertools import chain, combinations\n",
        "import numpy as np # numerical python used for data manipulation, same data type, numeric indexing\n",
        "import pandas as pd # similar to numpy but hetrogeneous data types, named indexing\n",
        "from sklearn.metrics import confusion_matrix # to show the classification performance\n",
        "from matplotlib import pyplot as plt  # used for plotting figures\n",
        "import random # used for random number generation\n",
        "import seaborn as sns # used for plotting cooler graphs than matplotlib\n",
        "# output | all the required libraries are imported here in this cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8PHZV98F4fs"
      },
      "source": [
        "\n",
        "\n",
        "# **SAMPLING RATES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jvjsxOap_kgY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['id00b70b13.csv', 'id079c763c.csv', 'id1165e00c.csv', 'id1c7e64ad.csv', 'id1f372081.csv', 'id34e056c8.csv', 'id37a54bbf.csv', 'id3e3e50c7.csv', 'id4ea159a8.csv', 'id5308a7d6.csv', 'id5993bf4a.csv', 'id650857ca.csv', 'id687ab496.csv', 'id7c20ee7a.csv', 'id82b9735c.csv', 'id86237981.csv', 'id8af5374b.csv', 'id8e66893c.csv', 'id9603e9c3.csv', 'ida61e8ddf.csv', 'idabd0c53c.csv', 'idb221f542.csv', 'idbae5a811.csv', 'idc735fc09.csv', 'idc91a49d0.csv', 'idd80ac2b4.csv', 'idecc9265e.csv', 'idf1ce9a0f.csv', 'idf540d82b.csv', 'idf5e3678b.csv', 'idfc5f05e4.csv', 'idff99de96.csv']\n",
            "{'id00b70b13.csv': 'User1', 'id079c763c.csv': 'User2', 'id1165e00c.csv': 'User3', 'id1c7e64ad.csv': 'User4', 'id1f372081.csv': 'User5', 'id34e056c8.csv': 'User6', 'id37a54bbf.csv': 'User7', 'id3e3e50c7.csv': 'User8', 'id4ea159a8.csv': 'User9', 'id5308a7d6.csv': 'User10', 'id5993bf4a.csv': 'User11', 'id650857ca.csv': 'User12', 'id687ab496.csv': 'User13', 'id7c20ee7a.csv': 'User14', 'id82b9735c.csv': 'User15', 'id86237981.csv': 'User16', 'id8af5374b.csv': 'User17', 'id8e66893c.csv': 'User18', 'id9603e9c3.csv': 'User19', 'ida61e8ddf.csv': 'User20', 'idabd0c53c.csv': 'User21', 'idb221f542.csv': 'User22', 'idbae5a811.csv': 'User23', 'idc735fc09.csv': 'User24', 'idc91a49d0.csv': 'User25', 'idd80ac2b4.csv': 'User26', 'idecc9265e.csv': 'User27', 'idf1ce9a0f.csv': 'User28', 'idf540d82b.csv': 'User29', 'idf5e3678b.csv': 'User30', 'idfc5f05e4.csv': 'User31', 'idff99de96.csv': 'User32'}\n",
            "['id9603e9c3.csv', 'id1165e00c.csv']\n"
          ]
        }
      ],
      "source": [
        "DATA_PATH = \"/Users/amandaagambire/Desktop/Projects/gaitguard/data/accelerometry-data/raw_accelerometry_data\"\n",
        "# creating some dictionaries to make sure we have all the numbers in the dataframe, easier to do numpy and back\n",
        "#SENSORS NOT NEEDED BECAUSE ONLY ACCELEROMETER IS USED TO COOLLECT DATA\n",
        "#Sensor = {'clean_LAcc.txt':1, 'clean_Gyr.txt':2, 'clean_Mag.txt':3, 'clean_RVec.txt':4}\n",
        "USERS = {}\n",
        "\n",
        "USER_FOLDER_LIST = sorted([f for f in os.listdir(DATA_PATH) if f.endswith(\".csv\")]) # list of all the folders for the path, IOW: list of all the users in the database.\n",
        "print(USER_FOLDER_LIST)\n",
        "\n",
        "for user in range(len(USER_FOLDER_LIST)) :\n",
        "  USERS[USER_FOLDER_LIST[user]] = f\"User{user + 1}\"\n",
        "print(USERS)\n",
        "# USERS = {filename: f\"User{idx + 1}\" for idx, filename in enumerate(USER_FOLDER_LIST)}\n",
        "# print(\"User map:\", USERS)\n",
        "\n",
        "RANDOM_USERS = random.choices(USER_FOLDER_LIST, k=2)\n",
        "print(RANDOM_USERS)\n",
        "\n",
        "samplerate = 100\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzToWScWuXHM"
      },
      "source": [
        "# **Compute Sampling Rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojsynoIXubeG"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'user_files_path' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m unique_user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m unique_user_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43muser_files_path\u001b[49m:\n\u001b[1;32m     21\u001b[0m   user_files_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_PATH))\n\u001b[1;32m     22\u001b[0m   \u001b[38;5;66;03m# print(user_files_path)\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'user_files_path' is not defined"
          ]
        }
      ],
      "source": [
        "########################################\n",
        "import pandas\n",
        "import re\n",
        "\n",
        "# this function computes the mean sampling rate (samples per second) \n",
        "#for any given accelerometery file\n",
        "def get_mean_sampling_rate(raw_data): \n",
        "    num_samples = raw_data.shape[0]\n",
        "    # print(f'num_samples {num_samples}')\n",
        "    timestamps = raw_data['time']\n",
        "    num_unique_stamps = np.unique(timestamps).shape[0]\n",
        "    # print(f'num_unique_stamps {num_unique_stamps}')\n",
        "    return int(num_samples / num_unique_stamps)\n",
        "########################################\n",
        "\n",
        "\n",
        "\n",
        "sampling_rates_dict = {}\n",
        "unique_user_id = 1\n",
        "unique_user_dict = {}\n",
        "for file in user_files_path:\n",
        "  user_files_path = os.listdir(os.path.join(DATA_PATH))\n",
        "  # print(user_files_path)\n",
        "  if '.DS_Store' in user_files_path:\n",
        "    user_files_path.remove('.DS_Store')\n",
        "  user_files_path.sort()\n",
        "  for user_file in user_files_path:\n",
        "    # setting up unique username and dictionary\n",
        "    # print('user_file:', user_file)\n",
        "    original_user_id = re.findall(r'\\d+', user_file)[0]\n",
        "    if original_user_id not in unique_user_dict:\n",
        "      unique_user_dict[original_user_id] = unique_user_id\n",
        "      unique_user_id = unique_user_id+1\n",
        "    file_path = os.path.join(DATA_PATH, device, sensor, user_file)\n",
        "    # print(f'=============================================={file_path}')\n",
        "    colnames = ['user_id', 'activity', 'time', 'x', 'y', 'z']\n",
        "    data_frame = pd.read_csv(file_path)\n",
        "    data_frame.columns = colnames\n",
        "    data_frame = data_frame[data_frame['activity']== 'A'] # using ONLY walking data which is labeled as A.\n",
        "    data_frame= data_frame[['time', 'x', 'y', 'z']]\n",
        "    # https://www.statology.org/pandas-remove-special-characters/\n",
        "    # removing the semicolon from end for z column values\n",
        "    # print(data_frame.dtypes)\n",
        "    data_frame['z'] = data_frame['z'].str.replace(';', '', regex=True)\n",
        "\n",
        "    # # some time columns were object such as for user 1600, converting it to int64\n",
        "    if data_frame.dtypes['time'] == 'object':\n",
        "      data_frame = data_frame.astype({\"time\": np.int64})\n",
        "\n",
        "    if data_frame.dtypes['x'] == 'object':\n",
        "      data_frame = data_frame.astype({\"x\": np.float64})\n",
        "\n",
        "    if data_frame.dtypes['y'] == 'object':\n",
        "      data_frame = data_frame.astype({\"y\": np.float64})\n",
        "\n",
        "    if data_frame.dtypes['z'] == 'object':\n",
        "      data_frame = data_frame.astype({\"z\": np.float64})\n",
        "\n",
        "    data_frame['time'] = data_frame['time']//10**9\n",
        "    # print(data_frame['time'].to_string())\n",
        "    sampling_rates_dict[device, sensor, unique_user_dict[original_user_id]] = get_mean_sampling_rate(data_frame)\n",
        "    # # print(data_frame['x'])\n",
        "    # data_frame['x'].plot()\n",
        "    # data_frame['y'].plot()\n",
        "    # data_frame['z'].plot()\n",
        "\n",
        "print(f'sampling_rates_dict: {sampling_rates_dict}')\n",
        "print(f'unique_user_dict: {unique_user_dict}')\n",
        "\n",
        "########This code produces sampling rate dictionary and user dictionary with more sane and ordered names!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-_8KuQcFxm0"
      },
      "source": [
        "# **EDA via plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWvg0es8F2aV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "random_start = random.randint(10000, 20000) # generating a random number between 10000 - 20000\n",
        "random_start2 = random.randint(20000,30000) # generating a random  number between 20000 and 30000, to avoid overlap with the previous window we start this with 400\n",
        "print(f'random_start:{random_start}')\n",
        "print(f'random_start2:{random_start2}')\n",
        "plt.rcParams['figure.figsize'] = (18, 5)\n",
        "\n",
        "\n",
        "def plot_lw():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_x (lw)')\n",
        "  lw_xyz['lw_x'].plot()\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_y (lw)')\n",
        "  lw_xyz['lw_y'].plot()\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_z (lw)')\n",
        "  lw_xyz['lw_z'].plot()\n",
        "  plt.figure()\n",
        "\n",
        "\n",
        "def plot_lh():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_x (lh)')\n",
        "  lh_xyz['lh_x'].plot()\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_y (lh)')\n",
        "  lh_xyz['lh_y'].plot()\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_z (lh)')\n",
        "  lh_xyz['lh_z'].plot()\n",
        "\n",
        "def plot_la():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_x (la)')\n",
        "  la_xyz['la_x'].plot()\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_y (la)')\n",
        "  la_xyz['la_y'].plot()\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_z (la)')\n",
        "  la_xyz['la_z'].plot()\n",
        "  plt.figure()\n",
        "\n",
        "\n",
        "def plot_ra():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_x (ra)')\n",
        "  ra_xyz['ra_x'].plot()\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_y (ra)')\n",
        "  ra_xyz['ra_y'].plot()\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  ax.title.set_text('user '+ USERS[user] + '_z (ra)')\n",
        "  ra_xyz['ra_z'].plot()\n",
        "  plt.figure()\n",
        "\n",
        "#\n",
        "# for user in USER_FOLDER_LIST:\n",
        "for user in RANDOM_USERS:\n",
        "  # make file path for each user\n",
        "  file_path = os.path.join(DATA_PATH, user)\n",
        "  all_data = pd.read_csv(file_path)\n",
        "\n",
        "  #only select rows with activity column as 1(represents walking as the activity)\n",
        "  raw_data = all_data[all_data['activity'] == 1]\n",
        "\n",
        "  #reset the index to make it unifomed & easier to select random ustart\n",
        "  raw_data = raw_data.reset_index()\n",
        "  raw_data = raw_data.drop(columns = 'index')\n",
        "  print(user ,raw_data.shape)\n",
        "  # print(raw_data.head())\n",
        "  # print(raw_data.tail())\n",
        "\n",
        "  # basically we will plot 10 seconds of data to see how many steps in 10 seconds and how are they different among users\n",
        "\n",
        "  raw_data = raw_data.iloc[random_start:random_start + int(samplerate*10)] # slicing the dataframe\n",
        "\n",
        "  lw_xyz = raw_data[['lw_x', 'lw_y','lw_z']]\n",
        "  lh_xyz = raw_data[['lh_x', 'lh_y','lh_z']]\n",
        "  la_xyz = raw_data[['la_x', 'la_y','la_z']]\n",
        "  ra_xyz = raw_data[['ra_x', 'ra_y','ra_z']]\n",
        "\n",
        "  plot_lh()\n",
        "  plot_la()\n",
        "  plot_lw()\n",
        "  plot_ra()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkGc66xCwqLg"
      },
      "source": [
        "# **DATA SEGMENTATION | WINDOWING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "efuCF42OxL0d",
        "outputId": "61fd8725-ecc9-44d2-b83a-98573c878366"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5941734fd6f2>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mUSER_FOLDER_LIST\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Traversing user by user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;31m# if counter == 2:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m#   break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'USER_FOLDER_LIST' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "FRAME_OUTPUT_LOCATION = r'/content/drive/MyDrive/RESEARCH 2023/Data/accelerometry-data-walking-stair-climbing-and-driving/accelerometry_data_frames' # change this location to store the newely generated frames!\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "FRAME_LENGTH = 10  # in seconds\n",
        "OVERLAP = FRAME_LENGTH // 2  # in seconds\n",
        "# # Use the SAMPLING_RATES to figure out the exact cut points to make the frame from the data\n",
        "LOCATION = ['lw', 'lh', 'la', 'ra']\n",
        "counter = 0 # just to stop the loop from running for all the users while debugging\n",
        "\n",
        "\n",
        "for user in USER_FOLDER_LIST: # Traversing user by user\n",
        "  # if counter == 2:\n",
        "  #   break\n",
        "  # counter = counter+1\n",
        "  print(f'working on {user}..have some patience')\n",
        "  user_frames = np.empty((0, 4), float)\n",
        "  file_path = os.path.join(DATA_PATH, user)\n",
        "  all_data = pd.read_csv(file_path)\n",
        "  #only select rows with activity column as 1(represents walking as the activity)\n",
        "  raw_data = all_data[all_data['activity'] == 1]\n",
        "  #reset & drop old index\n",
        "  raw_data = raw_data.reset_index()\n",
        "  raw_data = raw_data.drop(columns = 'index')\n",
        "  #print(user, raw_data.shape)\n",
        "\n",
        "  lw_xyz = raw_data[['lw_x', 'lw_y','lw_z']]\n",
        "  lh_xyz = raw_data[['lh_x', 'lh_y','lh_z']]\n",
        "  la_xyz = raw_data[['la_x', 'la_y','la_z']]\n",
        "  ra_xyz = raw_data[['ra_x', 'ra_y','ra_z']]\n",
        "  for location in LOCATION:\n",
        "    #print(user, location)\n",
        "    select_data = raw_data.loc[:,[location+'_x', location+'_y', location+'_z']] # slicing the timestamps away, we dont need it as we know the sampling rates.\n",
        "    samplerate = 100\n",
        "    begin_end_noise = samplerate*30 # discard noisy data for the first 30 seconds\n",
        "    frame_id = 1\n",
        "    for start_index in range(begin_end_noise, select_data.shape[0]-begin_end_noise, OVERLAP*samplerate):\n",
        "      end_index = start_index+FRAME_LENGTH * samplerate\n",
        "      #print(f'frame:{frame_id}, start from :{start_index}, ends at {end_index}')\n",
        "      curr_frame = select_data.iloc[start_index:end_index]\n",
        "      #print(f'data for user: {USERS[user]}, frame: {frame_id}')\n",
        "      #curr_frame['user'] = USERS[user]\n",
        "      curr_frame['frame_id'] = frame_id\n",
        "      frame_id = frame_id+1 # increasing to number the next frame.\n",
        "      user_frames = np.vstack((user_frames, curr_frame.values))\n",
        "    current_user_df = pd.DataFrame(user_frames, columns=[location+'_x', location+'_y', location+'_z', 'frame_id'])\n",
        "    current_user_df.reset_index()\n",
        "    #current_user_df['user'] = current_user_df['user'].astype('int')\n",
        "    current_user_df['frame_id'] = current_user_df['frame_id'].astype('int')\n",
        "    #print(f'current_user_df shape:{current_user_df.shape}')\n",
        "    #print(f'current_user_df head:{current_user_df.to_string()}')\n",
        "    # current_user_df.to_csv(os.path.join(FRAME_OUTPUT_LOCATION, location, 'User'+USERS[user]+'.csv'))\n",
        "\n",
        "\n",
        "# # # Userwise framed (segmented) data is saved\n",
        "# # # To run the following code on any dataset, it is essential that you transform the dataset in the format that this code produces\n",
        "# # # columns=['x', 'y', 'z', 'user', 'session', 'sensor', 'frame_id'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjdZty1IyNrN"
      },
      "source": [
        "# **PROCESSING | SMOOTHING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3xY77MvyVzk"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = (21, 5)\n",
        "\n",
        "raw_data = raw_data.iloc[random_start:random_start + 400] # slicing the dataframe\n",
        "\n",
        "\n",
        "def plot_lw():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  ax.title.set_text(USERS[user]+'_x (lw)')\n",
        "  lw_xyz['lw_x'].rolling(5, min_periods=1).sum().plot()\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  ax.title.set_text(USERS[user]+'_y (lw)')\n",
        "  lw_xyz['lw_y'].rolling(5, min_periods=1).sum().plot()\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  ax.title.set_text(USERS[user]+'_z (lw)')\n",
        "  lw_xyz['lw_z'].rolling(5, min_periods=1).sum().plot()\n",
        "  plt.figure()\n",
        "\n",
        "def plot_la():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  ax.title.set_text(USERS[user]+'_x (la)')\n",
        "  la_xyz['la_x'].rolling(5, min_periods=1).sum().plot()\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  ax.title.set_text(USERS[user]+'_y (la)')\n",
        "  la_xyz['la_y'].rolling(5, min_periods=1).sum().plot()\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  ax.title.set_text(USERS[user]+'_z (la)')\n",
        "  la_xyz['la_z'].rolling(5, min_periods=1).sum().plot()\n",
        "  plt.figure()\n",
        "\n",
        "def plot_lh():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  ax.title.set_text(USERS[user]+'_x (lh)')\n",
        "  lh_xyz['lh_x'].rolling(5, min_periods=1).sum().plot()\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  ax.title.set_text(USERS[user]+'_y (lh)')\n",
        "  lh_xyz['lh_y'].rolling(5, min_periods=1).sum().plot()\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  ax.title.set_text(USERS[user]+'_z (lh)')\n",
        "  lh_xyz['lh_z'].rolling(5, min_periods=1).sum().plot()\n",
        "  plt.figure()\n",
        "\n",
        "def plot_ra():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  ax.title.set_text(USERS[user]+'_x (ra)')\n",
        "  ra_xyz['ra_x'].rolling(5, min_periods=1).sum().plot()\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  ax.title.set_text(USERS[user]+'_y (ra)')\n",
        "  ra_xyz['ra_y'].rolling(5, min_periods=1).sum().plot()\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  ax.title.set_text(USERS[user]+'_z (ra)')\n",
        "  ra_xyz['ra_z'].rolling(5, min_periods=1).sum().plot()\n",
        "  plt.figure()\n",
        "\n",
        "\n",
        "for user in RANDOM_USERS:\n",
        "  #, sharex='col', sharey='row')\n",
        "  #for sensor in SENSOR_FILES[0:1]:\n",
        "  file_path = os.path.join(DATA_PATH, user)\n",
        "  raw_data = pd.read_csv(file_path)\n",
        "  raw_data = raw_data.iloc[random_start:random_start + 400] # slicing the dataframe\n",
        "  lw_xyz = raw_data[['lw_x', 'lw_y','lw_z']]\n",
        "  lh_xyz = raw_data[['lh_x', 'lh_y','lh_z']]\n",
        "  la_xyz = raw_data[['la_x', 'la_y','la_z']]\n",
        "  ra_xyz = raw_data[['ra_x', 'ra_y','ra_z']]\n",
        "  plot_lw()\n",
        "  plot_lh()\n",
        "  plot_la()\n",
        "  plot_ra()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcucTFxl207b"
      },
      "source": [
        "# **EDA via density plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bS_sKet3MQb"
      },
      "outputs": [],
      "source": [
        "for user in RANDOM_USERS:\n",
        "  file_path = os.path.join(DATA_PATH, user)\n",
        "  raw_data = pd.read_csv(file_path)\n",
        "  raw_data = raw_data.iloc[random_start:random_start+300].rolling(5, min_periods=1).sum()\n",
        "\n",
        "  lw_xyz.hist(bins=15, figsize=(15, 5), layout=(2, 4))\n",
        "  lh_xyz.hist(bins=15, figsize=(15, 5), layout=(2, 4))\n",
        "  la_xyz.hist(bins=15, figsize=(15, 5), layout=(2, 4))\n",
        "  ra_xyz.hist(bins=15, figsize=(15, 5), layout=(2, 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcX0co6FzB_c"
      },
      "source": [
        "\n",
        "# **EDA via KDE plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P71tT-JEzJP9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_lw():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  lw_xyz['lw_x'].plot.kde(title=USERS[user]+'_x',bw_method=.1)\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  lw_xyz['lw_y'].plot.kde(title=USERS[user]+'_y',bw_method=.1)\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  lw_xyz['lw_z'].plot.kde(title=USERS[user]+'_z',bw_method=.1)\n",
        "  plt.figure()\n",
        "\n",
        "def plot_la():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  la_xyz['la_x'].plot.kde(title=USERS[user]+'_x',bw_method=.1)\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  la_xyz['la_y'].plot.kde(title=USERS[user]+'_y',bw_method=.1)\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  la_xyz['la_z'].plot.kde(title=USERS[user]+'_z',bw_method=.1)\n",
        "  plt.figure()\n",
        "\n",
        "def plot_lh():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  lh_xyz['lh_x'].plot.kde(title=USERS[user]+'_x',bw_method=.1)\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  lh_xyz['lh_y'].plot.kde(title=USERS[user]+'_y',bw_method=.1)\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  lh_xyz['lh_z'].plot.kde(title=USERS[user]+'_z',bw_method=.1)\n",
        "  plt.figure()\n",
        "\n",
        "def plot_ra():\n",
        "  fig, ax = plt.subplots(1, 3)\n",
        "  ax = fig.add_subplot(1, 3, 1)\n",
        "  ra_xyz['ra_x'].plot.kde(title=USERS[user]+'_x',bw_method=.1)\n",
        "  ax = fig.add_subplot(1, 3, 2)\n",
        "  ra_xyz['ra_y'].plot.kde(title=USERS[user]+'_y',bw_method=.1)\n",
        "  ax = fig.add_subplot(1, 3, 3)\n",
        "  ra_xyz['ra_z'].plot.kde(title=USERS[user]+'_zx',bw_method=.1)\n",
        "  plt.figure()\n",
        "\n",
        "\n",
        "for user in RANDOM_USERS:\n",
        "  #, sharex='col', sharey='row')\n",
        "  #for sensor in SENSOR_FILES[0:1]:\n",
        "  file_path = os.path.join(DATA_PATH, user)\n",
        "  raw_data = pd.read_csv(file_path)\n",
        "  raw_data = raw_data.iloc[random_start:random_start+300].rolling(5, min_periods=1).sum()\n",
        "\n",
        "  plot_lw()\n",
        "  plot_lh()\n",
        "  plot_la()\n",
        "  plot_ra()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
